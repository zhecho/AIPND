{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Derivates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Power Rule:\n",
    "\n",
    "$\\frac{df}{dx} = n.x^{n-1}$\n",
    "\n",
    "### Sum Rule:\n",
    "\n",
    "\n",
    "### Product Rule:\n",
    "\n",
    "\n",
    "### Chain Rule:\n",
    "\n",
    " $ \\frac{\\delta}{\\delta z}.p(q(z)) = \\frac{\\delta p}{\\delta q} . \\frac{\\delta q} { \\delta z} $\n",
    "\n",
    "### Functions\n",
    "\n",
    "\n",
    "- Sigmoid activation function\n",
    "\n",
    "$$\\sigma(x) = \\frac{1}{1+e^{-x}}$$\n",
    "\n",
    "- Output (prediction) formula\n",
    "\n",
    "$$\\hat{y} = \\sigma(w_1 x_1 + w_2 x_2 + b)$$\n",
    "\n",
    "- Error function\n",
    "\n",
    "$$Error(y, \\hat{y}) = - y \\log(\\hat{y}) - (1-y) \\log(1-\\hat{y})$$\n",
    "\n",
    "- The function that updates the weights\n",
    "\n",
    "$$ w_i \\longrightarrow w_i + \\alpha (y - \\hat{y}) x_i$$\n",
    "\n",
    "$$ b \\longrightarrow b + \\alpha (y - \\hat{y})$$\n",
    "\n",
    "\n",
    "\n",
    " - Sigmoid Derivate\n",
    " \n",
    " $$\\sigma(x) = \\frac{\\delta}{\\delta x}.\\frac{1}{1+e^{-x}} = \\frac{e^{-x}}{(1+e^{-x})^{2}} = \\frac{1}{1+e^{-x}}.\\frac{e^{-x}}{1+e^{-x}} = \\sigma(x)(1-\\sigma(x))$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Neural Networks\n",
    "## Perceptrons as Logical Operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nice!  You got it all correct.\n",
      "\n",
      " Input 1    Input 2    Linear Combination    Activation Output   Is Correct\n",
      "       0          0                  -0.6                    0          Yes\n",
      "       0          1                  -0.5                    0          Yes\n",
      "       1          0                  -0.1                    0          Yes\n",
      "       1          1                   0.0                    1          Yes\n"
     ]
    }
   ],
   "source": [
    "# AND perceptron\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# TODO: Set weight1, weight2, and bias\n",
    "weight1 = 0.5\n",
    "weight2 = 0.1\n",
    "bias = -0.6\n",
    "\n",
    "\n",
    "# DON'T CHANGE ANYTHING BELOW\n",
    "# Inputs and outputs\n",
    "test_inputs = [(0, 0), (0, 1), (1, 0), (1, 1)]\n",
    "correct_outputs = [False, False, False, True]\n",
    "outputs = []\n",
    "\n",
    "# Generate and check output\n",
    "for test_input, correct_output in zip(test_inputs, correct_outputs):\n",
    "    linear_combination = weight1 * test_input[0] + weight2 * test_input[1] + bias\n",
    "    output = int(linear_combination >= 0)\n",
    "    is_correct_string = 'Yes' if output == correct_output else 'No'\n",
    "    outputs.append([test_input[0], test_input[1], linear_combination, output, is_correct_string])\n",
    "\n",
    "# Print output\n",
    "num_wrong = len([output[4] for output in outputs if output[4] == 'No'])\n",
    "output_frame = pd.DataFrame(outputs, columns=['Input 1', '  Input 2', '  Linear Combination', '  Activation Output', '  Is Correct'])\n",
    "if not num_wrong:\n",
    "    print('Nice!  You got it all correct.\\n')\n",
    "else:\n",
    "    print('You got {} wrong.  Keep trying!\\n'.format(num_wrong))\n",
    "print(output_frame.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nice!  You got it all correct.\n",
      "\n",
      " Input 1    Input 2    Linear Combination    Activation Output   Is Correct\n",
      "       0          0                  -0.1                    0          Yes\n",
      "       0          1                   0.0                    1          Yes\n",
      "       1          0                   0.5                    1          Yes\n",
      "       1          1                   0.6                    1          Yes\n"
     ]
    }
   ],
   "source": [
    "# OR perceptron \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# TODO: Set weight1, weight2, and bias\n",
    "weight1 = 0.6\n",
    "weight2 = 0.1\n",
    "bias = -0.1\n",
    "\n",
    "\n",
    "# DON'T CHANGE ANYTHING BELOW\n",
    "# Inputs and outputs\n",
    "test_inputs = [(0, 0), (0, 1), (1, 0), (1, 1)]\n",
    "correct_outputs = [False,True,True,True]\n",
    "outputs = []\n",
    "\n",
    "# Generate and check output\n",
    "for test_input, correct_output in zip(test_inputs, correct_outputs):\n",
    "    linear_combination = weight1 * test_input[0] + weight2 * test_input[1] + bias\n",
    "    output = int(linear_combination >= 0)\n",
    "    is_correct_string = 'Yes' if output == correct_output else 'No'\n",
    "    outputs.append([test_input[0], test_input[1], linear_combination, output, is_correct_string])\n",
    "\n",
    "# Print output\n",
    "num_wrong = len([output[4] for output in outputs if output[4] == 'No'])\n",
    "output_frame = pd.DataFrame(outputs, columns=['Input 1', '  Input 2', '  Linear Combination', '  Activation Output', '  Is Correct'])\n",
    "if not num_wrong:\n",
    "    print('Nice!  You got it all correct.\\n')\n",
    "else:\n",
    "    print('You got {} wrong.  Keep trying!\\n'.format(num_wrong))\n",
    "print(output_frame.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Not perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this quiz, you'll set the weights (weight1, weight2) and bias bias to the values that calculate the NOT operation on the second input and ignores the first input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nice!  You got it all correct.\n",
      "\n",
      " Input 1    Input 2    Linear Combination    Activation Output   Is Correct\n",
      "       0          0                   0.2                    1          Yes\n",
      "       0          1                  -0.1                    0          Yes\n",
      "       1          0                   0.0                    1          Yes\n",
      "       1          1                  -0.3                    0          Yes\n"
     ]
    }
   ],
   "source": [
    "# Not Perceptron\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# TODO: Set weight1, weight2, and bias\n",
    "weight1 = -0.2\n",
    "weight2 = -0.3\n",
    "bias = 0.2\n",
    "\n",
    "\n",
    "# DON'T CHANGE ANYTHING BELOW\n",
    "# Inputs and outputs\n",
    "test_inputs = [(0, 0), (0, 1), (1, 0), (1, 1)]\n",
    "correct_outputs = [True, False, True, False]\n",
    "outputs = []\n",
    "\n",
    "# Generate and check output\n",
    "for test_input, correct_output in zip(test_inputs, correct_outputs):\n",
    "    linear_combination = weight1 * test_input[0] + weight2 * test_input[1] + bias\n",
    "    output = int(linear_combination >= 0)\n",
    "    is_correct_string = 'Yes' if output == correct_output else 'No'\n",
    "    outputs.append([test_input[0], test_input[1], linear_combination, output, is_correct_string])\n",
    "\n",
    "# Print output\n",
    "num_wrong = len([output[4] for output in outputs if output[4] == 'No'])\n",
    "output_frame = pd.DataFrame(outputs, columns=['Input 1', '  Input 2', '  Linear Combination', '  Activation Output', '  Is Correct'])\n",
    "if not num_wrong:\n",
    "    print('Nice!  You got it all correct.\\n')\n",
    "else:\n",
    "    print('You got {} wrong.  Keep trying!\\n'.format(num_wrong))\n",
    "print(output_frame.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.09003057317038046, 0.24472847105479764, 0.6652409557748219]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# L = [1,2,3,4,5,6,7,8.9,19.2,29,3,32.8,23.5]\n",
    "L = [5,6,7]\n",
    "def softmax(L):\n",
    "    result_list = list()\n",
    "    exp_sum = 0\n",
    "    for v in L:\n",
    "        exp_sum += np.exp(v)\n",
    "    for idx,value in enumerate(L):\n",
    "        result_list.append(np.exp(value)/exp_sum)\n",
    "    return result_list\n",
    "\n",
    "print(softmax(L))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.828313737302301\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Y = [1,1,0]\n",
    "# P = [0.8,0.7,0.1]\n",
    "\n",
    "Y=[1,0,1,1]\n",
    "P=[0.4,0.6,0.1,0.5]\n",
    "# Write a function that takes as input two lists Y, P,\n",
    "# and returns the float corresponding to their cross-entropy.\n",
    "def cross_entropy(Y, P):\n",
    "    CE = 0\n",
    "#     for idx_y,value_y in enumerate(Y):\n",
    "#         for idx_p,value_p in enumerate(P):\n",
    "#             if value_y == 1:\n",
    "#                 CE += value_y*(np.log(value_p))\n",
    "#             elif value_y == 0:\n",
    "#                 CE += (1-value_y)*np.log(1-value_p)\n",
    "    Y = np.float_(Y)\n",
    "    P = np.float_(P)\n",
    "    CE = -np.sum(Y * np.log(P) + (1 - Y) * np.log(1 - P))\n",
    "    return CE\n",
    "\n",
    "print(cross_entropy(Y,P))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\hat{y} = \\sigma(Wx + b )$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CE = -$\\frac{1}{m}\\sum_{i=1}^{m} y_i.ln(p_i) + (1 - y_i).ln(1- p_i )$\n",
    "\n",
    "Multi-Class\n",
    "\n",
    "\n",
    "CE = -$\\sum_{i=1}^{n} \\sum_{j=1}^{m} y_{ij}.ln(p_{ij})$\n",
    "\n",
    "m - number of classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log-Loss Error Function\n",
    "\n",
    "Error Function = -$\\frac{1}{m}\\sum_{i=1}^{m} y_i.ln(y_i) + (1 - y_i).ln(1-y_i)$\n",
    "\n",
    "Error Function = -$\\frac{1}{m}\\sum_{i=1}^{m}\\sum_{j=1}^{n} y_i . ln(y_i)$\n",
    "\n",
    "m - number of classess "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimize Error function\n",
    " E(W,b) = -$\\frac{1}{m}\\sum_{i=1}^{m} (1 - y_i).ln(1-\\sigma(Wx^{(0)} + b) + y_i.ln(\\sigma(Wx^{(0)} + b )$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent with Squared Errors Function (sum of the squared errors SSE)\n",
    "\n",
    "$E_{sse} = \\frac{1}{2}\\sum_{\\mu}\\sum_{j}[y_{i}^{\\mu} - \\hat{y}_{j}^{\\mu}]^{2}$ \n",
    "\n",
    "or \n",
    "\n",
    "$E_{sse}= \\frac{1}{2}\\sum_{\\mu}\\sum_{j}[y_{i}^{\\mu} - f(\\sum_{i}w_{ij}x_{i}^{\\mu})]^{2} $\n",
    "\n",
    "Where y - True value and $\\hat{y}$ - prediction; j represents the output units of the network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent : The Code\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network output:\n",
      "0.6899744811276125\n",
      "Amount of Error:\n",
      "-0.1899744811276125\n",
      "Change in Weights:\n",
      "[-0.02031869 -0.04063738 -0.06095608 -0.08127477]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    Calculate sigmoid\n",
    "    \"\"\"\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def sigmoid_prime(x):\n",
    "    \"\"\"\n",
    "    # Derivative of the sigmoid function\n",
    "    \"\"\"\n",
    "    return sigmoid(x) * (1 - sigmoid(x))\n",
    "\n",
    "learnrate = 0.5\n",
    "x = np.array([1, 2, 3, 4])\n",
    "y = np.array(0.5)\n",
    "\n",
    "# Initial weights\n",
    "w = np.array([0.5, -0.5, 0.3, 0.1])\n",
    "\n",
    "### Calculate one gradient descent step for each weight\n",
    "### Note: Some steps have been consolidated, so there are\n",
    "###       fewer variable names than in the above sample code\n",
    "\n",
    "# TODO: Calculate the node's linear combination of inputs and weights\n",
    "# h =  x[0]*w[0] + x[1]*w[1]\n",
    "h = np.dot(x, w)\n",
    "\n",
    "# TODO: Calculate output of neural network\n",
    "nn_output = sigmoid(h)\n",
    "\n",
    "# TODO: Calculate error of neural network\n",
    "error = y - nn_output\n",
    "\n",
    "# TODO: Calculate the error term\n",
    "#       Remember, this requires the output gradient, which we haven't\n",
    "#       specifically added a variable for.\n",
    "error_term = error * sigmoid_prime(h)\n",
    "\n",
    "# TODO: Calculate change in weights\n",
    "del_w = learnrate * error_term * x\n",
    "\n",
    "print('Neural Network output:')\n",
    "print(nn_output)\n",
    "print('Amount of Error:')\n",
    "print(error)\n",
    "print('Change in Weights:')\n",
    "print(del_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
